{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPAssignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IeE2uCBYWly",
        "colab_type": "text"
      },
      "source": [
        "Mouting the google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQFNAidJYGSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d73ff23-8e05-41fd-cdf2-82d71d527d38"
      },
      "source": [
        "# mounting the drive  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1htJPmRYr_m",
        "colab_type": "text"
      },
      "source": [
        "Importing all the required packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLkIMzmAYyPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "44bfc0bf-3b5e-49e1-f3c1-bb820947a721"
      },
      "source": [
        "import pandas as pd   # for reading the dataset\n",
        "from sklearn.model_selection import train_test_split # for spliting the dataset into testing and training phases\n",
        "import numpy as np   # for datamanuplation operations.\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "import nltk\n",
        "import random"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgxrXManZTyW",
        "colab_type": "text"
      },
      "source": [
        "Importing the dataset by using pandas and storing it in the data_set variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-oghhyZZQiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_set = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apUz97OeZxn9",
        "colab_type": "text"
      },
      "source": [
        "Displaying both the initial data and data after once the preprocessing is done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35Nix9PZhuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "10481c7c-1d51-4b2e-db65-5a7385e42c09"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re \n",
        "\n",
        "pd.set_option('max_colwidth',400)\n",
        "\n",
        "wordnet = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations = \"?:!.,;-()\"\n",
        "\n",
        "raw_reviews = data_set.Phrase.values\n",
        "cleaned_reviews = []\n",
        "\n",
        "for i in range(len(raw_reviews)):\n",
        "  review = str(raw_reviews[i])\n",
        "  review=re.sub('[^a-zA-Z]',' ',review)\n",
        "  review=[wordnet.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "  review=' '.join(review)\n",
        "  cleaned_reviews.append(review)\n",
        "\n",
        "data_set['cleaned_reviews'] = cleaned_reviews\n",
        "\n",
        "data_set.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>cleaned_reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                         cleaned_reviews\n",
              "0         1  ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1         2  ...                                                                                                            a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                                                                                                                                a series\n",
              "3         4  ...                                                                                                                                                                                       a\n",
              "4         5  ...                                                                                                                                                                                  series\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLyv5PYEaGw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_set.cleaned_reviews.values\n",
        "Y = to_categorical(data_set.Sentiment.values)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=4000,stop_words = None, ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcXs84XOaRz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I51cpzQiaUvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x_train_np = x_train.toarray()\n",
        "y_train_np = np.array(y_train)\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U25laRXqaZkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.expand_dims(x_train_np, axis=2)\n",
        "x_test = np.expand_dims(x_test_np, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_oRfz3racrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "def cnn(data_x):\n",
        "  #Convolution layer 1\n",
        "  model.add(Conv1D(filters = 64, kernel_size=3, activation='relu', input_shape=(data_x.shape[1],1)))\n",
        "  #MaxPool layer\n",
        "  model.add(MaxPooling1D(pool_size =2))\n",
        "  #Convolution layer 2\n",
        "  model.add(Conv1D(filters = 128, kernel_size=3, activation='relu'))\n",
        "  #MaxPool layer\n",
        "  model.add(MaxPooling1D(pool_size =2))\n",
        "  model.add(Flatten())\n",
        "  #Fully connected layer\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  #Dropout layer\n",
        "  model.add(Dropout(0.2))\n",
        "  #Output Layer\n",
        "  model.add(Dense(5, activation='softmax')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oeTQtVgaqdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuoY_GDFawBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaOoETVayvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn(x_train_np)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[metrics.categorical_accuracy,f1_m,precision_m, recall_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiQ_E7Vma3Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "211389bb-0ece-4305-f0e2-e45d68b9f007"
      },
      "source": [
        "history = model.fit(x_train, y_train_np, epochs=5, batch_size=128)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "109242/109242 [==============================] - 27s 251us/step - loss: 0.4105 - categorical_accuracy: 0.8253 - f1_m: 0.8244 - precision_m: 0.8428 - recall_m: 0.8071\n",
            "Epoch 2/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.4087 - categorical_accuracy: 0.8260 - f1_m: 0.8247 - precision_m: 0.8428 - recall_m: 0.8075\n",
            "Epoch 3/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.4074 - categorical_accuracy: 0.8272 - f1_m: 0.8257 - precision_m: 0.8436 - recall_m: 0.8087\n",
            "Epoch 4/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.4042 - categorical_accuracy: 0.8270 - f1_m: 0.8260 - precision_m: 0.8437 - recall_m: 0.8092\n",
            "Epoch 5/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.4039 - categorical_accuracy: 0.8276 - f1_m: 0.8269 - precision_m: 0.8446 - recall_m: 0.8100\n",
            "Epoch 6/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.4031 - categorical_accuracy: 0.8291 - f1_m: 0.8275 - precision_m: 0.8455 - recall_m: 0.8104\n",
            "Epoch 7/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.4004 - categorical_accuracy: 0.8287 - f1_m: 0.8277 - precision_m: 0.8451 - recall_m: 0.8111\n",
            "Epoch 8/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.3982 - categorical_accuracy: 0.8298 - f1_m: 0.8287 - precision_m: 0.8464 - recall_m: 0.8118\n",
            "Epoch 9/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3984 - categorical_accuracy: 0.8290 - f1_m: 0.8278 - precision_m: 0.8455 - recall_m: 0.8110\n",
            "Epoch 10/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3988 - categorical_accuracy: 0.8294 - f1_m: 0.8283 - precision_m: 0.8463 - recall_m: 0.8113\n",
            "Epoch 11/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3944 - categorical_accuracy: 0.8318 - f1_m: 0.8309 - precision_m: 0.8481 - recall_m: 0.8145\n",
            "Epoch 12/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3923 - categorical_accuracy: 0.8320 - f1_m: 0.8310 - precision_m: 0.8486 - recall_m: 0.8143\n",
            "Epoch 13/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3918 - categorical_accuracy: 0.8325 - f1_m: 0.8315 - precision_m: 0.8486 - recall_m: 0.8152\n",
            "Epoch 14/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3877 - categorical_accuracy: 0.8337 - f1_m: 0.8332 - precision_m: 0.8503 - recall_m: 0.8170\n",
            "Epoch 15/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3886 - categorical_accuracy: 0.8329 - f1_m: 0.8324 - precision_m: 0.8489 - recall_m: 0.8165\n",
            "Epoch 16/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3879 - categorical_accuracy: 0.8346 - f1_m: 0.8339 - precision_m: 0.8512 - recall_m: 0.8174\n",
            "Epoch 17/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3861 - categorical_accuracy: 0.8334 - f1_m: 0.8325 - precision_m: 0.8498 - recall_m: 0.8160\n",
            "Epoch 18/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3864 - categorical_accuracy: 0.8344 - f1_m: 0.8337 - precision_m: 0.8508 - recall_m: 0.8175\n",
            "Epoch 19/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.3830 - categorical_accuracy: 0.8349 - f1_m: 0.8346 - precision_m: 0.8516 - recall_m: 0.8183\n",
            "Epoch 20/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3831 - categorical_accuracy: 0.8361 - f1_m: 0.8352 - precision_m: 0.8520 - recall_m: 0.8192\n",
            "Epoch 21/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3832 - categorical_accuracy: 0.8348 - f1_m: 0.8339 - precision_m: 0.8510 - recall_m: 0.8176\n",
            "Epoch 22/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3807 - categorical_accuracy: 0.8376 - f1_m: 0.8362 - precision_m: 0.8526 - recall_m: 0.8205\n",
            "Epoch 23/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3789 - categorical_accuracy: 0.8362 - f1_m: 0.8354 - precision_m: 0.8518 - recall_m: 0.8197\n",
            "Epoch 24/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3775 - categorical_accuracy: 0.8373 - f1_m: 0.8365 - precision_m: 0.8533 - recall_m: 0.8205\n",
            "Epoch 25/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3784 - categorical_accuracy: 0.8375 - f1_m: 0.8363 - precision_m: 0.8531 - recall_m: 0.8204\n",
            "Epoch 26/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3774 - categorical_accuracy: 0.8386 - f1_m: 0.8375 - precision_m: 0.8541 - recall_m: 0.8217\n",
            "Epoch 27/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3765 - categorical_accuracy: 0.8386 - f1_m: 0.8376 - precision_m: 0.8538 - recall_m: 0.8222\n",
            "Epoch 28/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3753 - categorical_accuracy: 0.8384 - f1_m: 0.8378 - precision_m: 0.8538 - recall_m: 0.8224\n",
            "Epoch 29/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3747 - categorical_accuracy: 0.8383 - f1_m: 0.8372 - precision_m: 0.8537 - recall_m: 0.8214\n",
            "Epoch 30/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3729 - categorical_accuracy: 0.8400 - f1_m: 0.8390 - precision_m: 0.8553 - recall_m: 0.8235\n",
            "Epoch 31/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.3730 - categorical_accuracy: 0.8390 - f1_m: 0.8387 - precision_m: 0.8547 - recall_m: 0.8234\n",
            "Epoch 32/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3708 - categorical_accuracy: 0.8400 - f1_m: 0.8394 - precision_m: 0.8549 - recall_m: 0.8245\n",
            "Epoch 33/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3694 - categorical_accuracy: 0.8414 - f1_m: 0.8411 - precision_m: 0.8570 - recall_m: 0.8258\n",
            "Epoch 34/50\n",
            "109242/109242 [==============================] - 27s 250us/step - loss: 0.3697 - categorical_accuracy: 0.8411 - f1_m: 0.8405 - precision_m: 0.8562 - recall_m: 0.8254\n",
            "Epoch 35/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3711 - categorical_accuracy: 0.8401 - f1_m: 0.8393 - precision_m: 0.8552 - recall_m: 0.8243\n",
            "Epoch 36/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3690 - categorical_accuracy: 0.8407 - f1_m: 0.8398 - precision_m: 0.8559 - recall_m: 0.8244\n",
            "Epoch 37/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3672 - categorical_accuracy: 0.8421 - f1_m: 0.8416 - precision_m: 0.8572 - recall_m: 0.8266\n",
            "Epoch 38/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3669 - categorical_accuracy: 0.8408 - f1_m: 0.8403 - precision_m: 0.8558 - recall_m: 0.8255\n",
            "Epoch 39/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3650 - categorical_accuracy: 0.8419 - f1_m: 0.8414 - precision_m: 0.8568 - recall_m: 0.8267\n",
            "Epoch 40/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3664 - categorical_accuracy: 0.8420 - f1_m: 0.8408 - precision_m: 0.8563 - recall_m: 0.8260\n",
            "Epoch 41/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3661 - categorical_accuracy: 0.8411 - f1_m: 0.8404 - precision_m: 0.8558 - recall_m: 0.8257\n",
            "Epoch 42/50\n",
            "109242/109242 [==============================] - 27s 249us/step - loss: 0.3650 - categorical_accuracy: 0.8421 - f1_m: 0.8413 - precision_m: 0.8571 - recall_m: 0.8261\n",
            "Epoch 43/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3651 - categorical_accuracy: 0.8417 - f1_m: 0.8411 - precision_m: 0.8563 - recall_m: 0.8266\n",
            "Epoch 44/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3635 - categorical_accuracy: 0.8424 - f1_m: 0.8419 - precision_m: 0.8568 - recall_m: 0.8277\n",
            "Epoch 45/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3607 - categorical_accuracy: 0.8436 - f1_m: 0.8431 - precision_m: 0.8579 - recall_m: 0.8289\n",
            "Epoch 46/50\n",
            "109242/109242 [==============================] - 27s 248us/step - loss: 0.3621 - categorical_accuracy: 0.8430 - f1_m: 0.8427 - precision_m: 0.8574 - recall_m: 0.8285\n",
            "Epoch 47/50\n",
            "109242/109242 [==============================] - 27s 247us/step - loss: 0.3608 - categorical_accuracy: 0.8435 - f1_m: 0.8432 - precision_m: 0.8586 - recall_m: 0.8283\n",
            "Epoch 48/50\n",
            "109242/109242 [==============================] - 28s 255us/step - loss: 0.3613 - categorical_accuracy: 0.8431 - f1_m: 0.8427 - precision_m: 0.8582 - recall_m: 0.8280\n",
            "Epoch 49/50\n",
            "109242/109242 [==============================] - 28s 255us/step - loss: 0.3605 - categorical_accuracy: 0.8433 - f1_m: 0.8425 - precision_m: 0.8578 - recall_m: 0.8280\n",
            "Epoch 50/50\n",
            "109242/109242 [==============================] - 28s 255us/step - loss: 0.3583 - categorical_accuracy: 0.8449 - f1_m: 0.8448 - precision_m: 0.8596 - recall_m: 0.8306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPA9Oc5Qa7Dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "af4e7864-c3f4-4f6c-ee41-dfd36d366118"
      },
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy \" + str(accuracy) + \":\\n\\ff1_score = \" + str(f1_score) +\n",
        "          \"\\nPrecision = \" + str(precision) + \"\\nRecall = \" + str(recall))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.6195693963860054:\n",
            "\ff1_score = 0.6169272960390864\n",
            "Precision = 0.623162252807552\n",
            "Recall = 0.6110043145798625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6IWJEMBa9rJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3960aeac-766c-46ca-9c8c-0f16261cc62c"
      },
      "source": [
        "model.save(\"1104076_1d_conv_reg\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}